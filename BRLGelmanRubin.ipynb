{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import hamming\n",
    "from time import time\n",
    "\n",
    "#Import the helper functions and the samplers\n",
    "from BasicFunctions import *\n",
    "from TabuSampler import tabu_sampler\n",
    "from ZanellaSampler import zanella_sampler\n",
    "from RandomWalkSampler import rw_sampler\n",
    "from PointwiseSampler import pointwise_sampler \n",
    "from GelmanRubinDiagnostic import *\n",
    "\n",
    "\n",
    "#Autocorrelation function as implemented by Power and Goldman\n",
    "@numba.njit()\n",
    "def autocorr(x, lags):\n",
    "    mean=np.mean(x)\n",
    "    var=np.var(x)\n",
    "    xp=x-mean\n",
    "    corr=[1. if l==0 else np.sum(xp[l:]*xp[:-l])/len(x)/var for l in lags]\n",
    "    return np.array(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The golden truth p_match:  0.9498269391233346\n",
      "The number of generators:  1980\n",
      "The first record of the x database:\n",
      "[4. 2. 1. 3. 1. 3. 4. 2. 2. 2. 2. 3. 4. 1. 1.]\n",
      "The first record of the y database:\n",
      "[3. 3. 4. 2. 2. 2. 2. 1. 4. 4. 4. 4. 4. 3. 2.]\n",
      "The golden truth M vector: \n",
      "[21. 44.  1. 42. 12. 22. 35.  0. 43. 11.  4. 19. 33. 28. 14. 38.  2. 27.\n",
      " 34. 24. 16. 40. 36.  9. 31. 10.  7. 18. 17. 25. 20. 37. 26. 15. 29. 13.\n",
      "  5. 32.  8. 23.  3.  0.  6. 41. 30.]\n"
     ]
    }
   ],
   "source": [
    "#Generating the database\n",
    "from DatabaseClass import create_databases\n",
    "\n",
    "#Global parameters used\n",
    "lmbd = 50\n",
    "l = 15 #The number of categories for each record\n",
    "p_cat = np.array([0.05, 0.15, 0.4, 0.2, 0.2]) #The pval vector for each category\n",
    "beta = 0.3\n",
    "\n",
    "p_match, x, y, M_truth, M_reverse_truth = create_databases(lmbd, l, p_cat, beta)\n",
    "\n",
    "#Other parameters that are needed\n",
    "N_1 = len(x)\n",
    "N_2 = len(y)\n",
    "num_gens = N_1*N_2\n",
    "\n",
    "\n",
    "print(\"The golden truth p_match: \", p_match)\n",
    "print(\"The number of generators: \", num_gens)\n",
    "print(\"The first record of the x database:\")\n",
    "print(x[0, :])\n",
    "print(\"The first record of the y database:\")\n",
    "print(y[0,:])\n",
    "print(\"The golden truth M vector: \")\n",
    "print(M_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Barker balancing function\n",
    "g = lambda t: t/(1+t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "The starting M:  [[11.  0.  0.  0.  0.  0. 34.  7.  0. 16.  0.  0.  0. 21.  8.  0.  0.  0.\n",
      "   0.  0.  0.  3.  0. 27.  0. 25.  0.  2. 17.  0. 14.  0. 24.  0. 44.  0.\n",
      "   0.  0.  0. 28.  0. 30.  0.  0. 32.]\n",
      " [ 0.  6. 36. 11.  0.  0.  0. 30.  0.  0.  0.  0.  0.  0. 18.  0.  0.  0.\n",
      "   0.  0.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 35.  0.\n",
      "   0. 41.  0.  0.  0.  0.  0. 10.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 17. 34.  0. 18.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  8.  0. 28.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 29.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 28. 24. 20. 34.  0.  0.  0.  9.  3. 23.  0.  0.  0. 40.  4.\n",
      "   0.  0.  0. 35. 26.  0.  0.  0.  7.  0. 17.  0. 18. 12.  0. 44.  0. 13.\n",
      "  14.  0.  0. 42.  0. 19.  0.  0. 39.]\n",
      " [ 0.  0. 25.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 33. 14.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0. 43.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0. 27.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 20.  4.  0.  0.  0.  0.  0.  0.  0. 34.  0.  0.  0.\n",
      "  13.  0. 18.  0.  0. 23.  0.  0.  0.  0.  0.  0. 36. 28.  0.  0.  0.  0.\n",
      "   0. 12.  8. 25.  0.  0.  0.  5. 11.]\n",
      " [ 0.  0.  0. 23.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 20.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 40.  6.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  2.  0.  0.  0. 44.  0.  0.  0.  0. 24.  0.  0.  0.  0.\n",
      "   7.  0.  0.  0.  0. 36.  0.  3.  0.  0.  0.  0.  0.  0. 37.  0.  0.  0.\n",
      "   8.  1.  0.  0. 29.  0.  0.  0.  0.]]\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "num_rw = 1000\n",
    "m = 10\n",
    "\n",
    "energy_rate, starting_M, starting_M_reverse = start_sequences(N_1, N_2, lmbd, p_match, p_cat, l, beta, x, y, N, num_rw, m)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"The starting M: \", starting_M)\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the random walk R value from the Gelman-Rubin diagnostic\n",
    "# from RandomWalkSampler import *\n",
    "# n = int(1e3)\n",
    "# traces_rw = []\n",
    "# m = 10\n",
    "# for i in np.arange(0,m):\n",
    "#     #Run the sampler in this case\n",
    "#     trace, energy, hamming, num_acc, runtime = rw_sampler(2*n, N_1, N_2, lmbd, p_match, M_truth, starting_M[i,:], starting_M_reverse[i,:], p_cat, l, beta, x, y, print_rate=10)\n",
    "#     traces_rw.append(energy)\n",
    "    \n",
    "# #Testing the function to make the code scaleable\n",
    "# R_energy_rw = gelman_rubin(traces_rw, n, m)\n",
    "# print(\"-------------------------------------------------------------------\")\n",
    "# print(\"The scale reduction for the energy of the target_density: \",R_energy_rw)\n",
    "# print(\"-------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the Tabu sampler R value from the Gelman-Rubin diagnostic\n",
    "# n = int(1e3)\n",
    "# print_rate = 10\n",
    "# T = 15\n",
    "# thin_rate = 0.015\n",
    "# traces_t = []\n",
    "# m = 10\n",
    "# for i in np.arange(0,m):\n",
    "#     #Run the sampler in this case\n",
    "#     trace, energy, hamming, alpha, num_iter, runtime = tabu_sampler(N_1, N_2, num_gens, starting_M[i,:], starting_M_reverse[i,:], g,\n",
    "#                                                                     2*T, M_truth, thin_rate, print_rate, lmbd, p_match, l, p_cat, beta, x, y)\n",
    "#     traces_t.append(energy)\n",
    "    \n",
    "# #Testing the function to make the code scaleable\n",
    "# R_energy_t = gelman_rubin(traces_t, n, m)\n",
    "# print(\"-------------------------------------------------------------------\")\n",
    "# print(\"The scale reduction for the energy of the target_density: \",R_energy_t)\n",
    "# print(\"-------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.32\n",
      "Runtime:  0.62\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.84\n",
      "Runtime:  9.85\n",
      "Percent: [---------------------------------------->] 103%Runtime:  4.83\n",
      "Percent: [--------------------------------------> ] 98%Average excursion length:  27.0\n",
      "Runtime:  5.16\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.31\n",
      "Runtime:  0.57\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.81\n",
      "Runtime:  10.49\n",
      "Percent: [--------------------------------------> ] 98%Runtime:  6.42\n",
      "Percent: [------------------------------------>   ] 92%Average excursion length:  25.0\n",
      "Runtime:  4.68\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.275\n",
      "Runtime:  0.53\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.83\n",
      "Runtime:  10.85\n",
      "Percent: [--------------------------------------->] 99%Runtime:  4.6\n",
      "Percent: [--------------------------------------->] 99%Average excursion length:  15.0\n",
      "Runtime:  5.44\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.37\n",
      "Runtime:  0.44\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.8\n",
      "Runtime:  9.62\n",
      "Percent: [--------------------------------------> ] 97%Runtime:  5.58\n",
      "Percent: [------------------------------------->  ] 95%Average excursion length:  18.0\n",
      "Runtime:  5.57\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.295\n",
      "Runtime:  0.65\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.785\n",
      "Runtime:  10.25\n",
      "Percent: [------------------------------------>   ] 93%Runtime:  5.75\n",
      "Percent: [------------------------------------->  ] 96%Average excursion length:  24.0\n",
      "Runtime:  4.78\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.335\n",
      "Runtime:  0.57\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.81\n",
      "Runtime:  10.86\n",
      "Percent: [------------------------------------>   ] 92%Runtime:  6.44\n",
      "Percent: [------------------------------------->  ] 95%Average excursion length:  21.0\n",
      "Runtime:  6.15\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.345\n",
      "Runtime:  0.53\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.825\n",
      "Runtime:  10.24\n",
      "Percent: [---------------------------------------->] 102%Runtime:  6.74\n",
      "Percent: [------------------------------------>   ] 92%Average excursion length:  17.0\n",
      "Runtime:  5.01\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.285\n",
      "Runtime:  0.59\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.79\n",
      "Runtime:  9.99\n",
      "Percent: [------------------------------------>   ] 92%Runtime:  4.48\n",
      "Percent: [--------------------------------------> ] 97%Average excursion length:  15.0\n",
      "Runtime:  4.54\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.365\n",
      "Runtime:  0.56\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.835\n",
      "Runtime:  10.82\n",
      "Percent: [------------------------------------>   ] 93%Runtime:  7.29\n",
      "Percent: [---------------------------------------->] 102%Average excursion length:  23.0\n",
      "Runtime:  4.29\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.36\n",
      "Runtime:  0.57\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.85\n",
      "Runtime:  10.67\n",
      "Percent: [------------------------------------->  ] 96%Runtime:  5.23\n",
      "Percent: [------------------------------------>   ] 92%Average excursion length:  19.0\n",
      "Runtime:  5.51\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (random walk sampler):  2.2083128646601775\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (Pointwise sampler):  1.4768854609905617\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (Zanella sampler):  2.237627771225445\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (Tabu sampler):  1.4129576408099447\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Running the Gelman-Rubin diagnostic for all four samplers for N=100\n",
    "n = int(1e2)\n",
    "print_rate = 10\n",
    "T_z = 1.5\n",
    "T_t = 3.00\n",
    "thin_rate_t = 0.03\n",
    "thin_rate_z = 0.015\n",
    "traces_rw = []\n",
    "traces_pw = []\n",
    "traces_z = []\n",
    "traces_t = []\n",
    "m = 10\n",
    "for i in np.arange(0,m):\n",
    "    #Run the random walk sampler\n",
    "    trace_rw, energy_rw, hamming_rw, num_acc_rw, runtime_rw = rw_sampler(2*n, N_1, N_2, lmbd, p_match, M_truth, starting_M[i,:], starting_M_reverse[i,:], p_cat, l, beta, x, y, print_rate=10)\n",
    "    #Run the pointwise sampler\n",
    "    trace1_pw, energy_pw, hamming_pw, num_iter_pw, runtime_pw = pointwise_sampler(2*n, N_1, N_2, lmbd, p_match, g, M_truth, starting_M[i,:],\n",
    "                                                                              starting_M_reverse[i,:], p_cat, l, beta, x, y, print_rate)\n",
    "    \n",
    "    #Run the Zanella sampler\n",
    "    trace1_z, energy_z, hamming_z, num_iter_z, runtime_z = zanella_sampler(N_1, N_2,\n",
    "                                                                                num_gens,\n",
    "                                                                                starting_M[i,:], starting_M_reverse[i,:],\n",
    "                                                                                g, 2*T_z, M_truth,\n",
    "                                                                                thin_rate_z, print_rate, lmbd, p_match,\n",
    "                                                                                l, p_cat, beta, x, y)\n",
    "    \n",
    "    #Run the Tabu sampler\n",
    "    trace_t, energy_t, hamming_t, alpha_t, num_iter_t, runtime_t = tabu_sampler(N_1, N_2, num_gens, starting_M[i,:], starting_M_reverse[i,:], g,\n",
    "                                                                    2*T_t, M_truth, thin_rate_t, print_rate, lmbd, p_match, l, p_cat, beta, x, y)\n",
    "    traces_rw.append(energy_rw)\n",
    "    traces_pw.append(energy_pw)\n",
    "    traces_z.append(energy_z)\n",
    "    traces_t.append(energy_t)\n",
    "    \n",
    "#Testing the function to make the code scaleable\n",
    "R_energy_rw = gelman_rubin(traces_rw, n, m)\n",
    "R_energy_pw = gelman_rubin(traces_pw, n, m)\n",
    "R_energy_z = gelman_rubin(traces_z, n, m)\n",
    "R_energy_t = gelman_rubin(traces_t, n, m)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (random walk sampler): \",R_energy_rw)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (Pointwise sampler): \",R_energy_pw)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (Zanella sampler): \",R_energy_z)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (Tabu sampler): \",R_energy_t)\n",
    "print(\"-------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.04\n",
      "Runtime:  4.67\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.738\n",
      "Runtime:  57.17\n",
      "Percent: [--------------------------------------->] 101%Runtime:  17.54\n",
      "Percent: [--------------------------------------> ] 99%Average excursion length:  13.0\n",
      "Runtime:  19.63\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.021\n",
      "Runtime:  4.71\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.736\n",
      "Runtime:  54.16\n",
      "Percent: [--------------------------------------> ] 98%Runtime:  24.16\n",
      "Percent: [--------------------------------------->] 100%Average excursion length:  13.0\n",
      "Runtime:  25.75\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.022\n",
      "Runtime:  4.62\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.751\n",
      "Runtime:  56.89\n",
      "Percent: [------------------------------------->  ] 96%Runtime:  20.3\n",
      "Percent: [--------------------------------------->] 100%Average excursion length:  11.0\n",
      "Runtime:  16.26\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.023\n",
      "Runtime:  4.58\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.781\n",
      "Runtime:  57.79\n",
      "Percent: [--------------------------------------> ] 98%Runtime:  18.72\n",
      "Percent: [--------------------------------------> ] 98%Average excursion length:  14.0\n",
      "Runtime:  19.82\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.021\n",
      "Runtime:  4.37\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.753\n",
      "Runtime:  55.15\n",
      "Percent: [--------------------------------------->] 99%Runtime:  20.26\n",
      "Percent: [--------------------------------------->] 100%Average excursion length:  13.0\n",
      "Runtime:  20.47\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.028\n",
      "Runtime:  4.28\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.776\n",
      "Runtime:  54.43\n",
      "Percent: [--------------------------------------->] 100%Runtime:  20.04\n",
      "Percent: [--------------------------------------> ] 98%Average excursion length:  14.0\n",
      "Runtime:  21.41\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.032\n",
      "Runtime:  4.18\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.761\n",
      "Runtime:  53.39\n",
      "Percent: [--------------------------------------->] 99%Runtime:  17.75\n",
      "Percent: [--------------------------------------> ] 98%Average excursion length:  11.0\n",
      "Runtime:  16.63\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.023\n",
      "Runtime:  4.28\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.743\n",
      "Runtime:  53.22\n",
      "Percent: [--------------------------------------->] 99%Runtime:  16.92\n",
      "Percent: [--------------------------------------->] 100%Average excursion length:  11.0\n",
      "Runtime:  14.07\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.026\n",
      "Runtime:  4.38\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.741\n",
      "Runtime:  53.28\n",
      "Percent: [--------------------------------------> ] 98%Runtime:  22.2\n",
      "Percent: [--------------------------------------->] 99%Average excursion length:  12.0\n",
      "Runtime:  22.88\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.016\n",
      "Runtime:  4.32\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.761\n",
      "Runtime:  55.68\n",
      "Percent: [--------------------------------------->] 99%Runtime:  17.34\n",
      "Percent: [------------------------------------->  ] 96%Average excursion length:  13.0\n",
      "Runtime:  18.82\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (random walk sampler):  3.404163112428788\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (Pointwise sampler):  1.4859663364257891\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (Zanella sampler):  1.2428967589124926\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (Tabu sampler):  1.5915357226735731\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Running the Gelman-Rubin diagnostic for all four samplers for N=500\n",
    "n = int(5e2)\n",
    "print_rate = 10\n",
    "T_z = 7.5\n",
    "T_t = 15.0\n",
    "thin_rate_t = 0.03\n",
    "thin_rate_z = 0.015\n",
    "traces_rw = []\n",
    "traces_pw = []\n",
    "traces_z = []\n",
    "traces_t = []\n",
    "m = 10\n",
    "for i in np.arange(0,m):\n",
    "    #Run the random walk sampler\n",
    "    trace_rw, energy_rw, hamming_rw, num_acc_rw, runtime_rw = rw_sampler(2*n, N_1, N_2, lmbd, p_match, M_truth, starting_M[i,:], starting_M_reverse[i,:], p_cat, l, beta, x, y, print_rate=10)\n",
    "    #Run the pointwise sampler\n",
    "    trace1_pw, energy_pw, hamming_pw, num_iter_pw, runtime_pw = pointwise_sampler(2*n, N_1, N_2, lmbd, p_match, g, M_truth, starting_M[i,:],\n",
    "                                                                              starting_M_reverse[i,:], p_cat, l, beta, x, y, print_rate)\n",
    "    \n",
    "    #Run the Zanella sampler\n",
    "    trace1_z, energy_z, hamming_z, num_iter_z, runtime_z = zanella_sampler(N_1, N_2,\n",
    "                                                                                num_gens,\n",
    "                                                                                starting_M[i,:], starting_M_reverse[i,:],\n",
    "                                                                                g, 2*T_z, M_truth,\n",
    "                                                                                thin_rate_z, print_rate, lmbd, p_match,\n",
    "                                                                                l, p_cat, beta, x, y)\n",
    "    \n",
    "    #Run the Tabu sampler\n",
    "    trace_t, energy_t, hamming_t, alpha_t, num_iter_t, runtime_t = tabu_sampler(N_1, N_2, num_gens, starting_M[i,:], starting_M_reverse[i,:], g,\n",
    "                                                                    2*T_t, M_truth, thin_rate_t, print_rate, lmbd, p_match, l, p_cat, beta, x, y)\n",
    "    traces_rw.append(energy_rw)\n",
    "    traces_pw.append(energy_pw)\n",
    "    traces_z.append(energy_z)\n",
    "    traces_t.append(energy_t)\n",
    "    \n",
    "#Testing the function to make the code scaleable\n",
    "R_energy_rw = gelman_rubin(traces_rw, n, m)\n",
    "R_energy_pw = gelman_rubin(traces_pw, n, m)\n",
    "R_energy_z = gelman_rubin(traces_z, n, m)\n",
    "R_energy_t = gelman_rubin(traces_t, n, m)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (random walk sampler): \",R_energy_rw)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (Pointwise sampler): \",R_energy_pw)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (Zanella sampler): \",R_energy_z)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (Tabu sampler): \",R_energy_t)\n",
    "print(\"-------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.026\n",
      "Runtime:  8.58\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.756\n",
      "Runtime:  109.53\n",
      "Percent: [--------------------------------------->] 100%Runtime:  37.07\n",
      "Percent: [--------------------------------------->] 99%Average excursion length:  13.0\n",
      "Runtime:  43.73\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.0305\n",
      "Runtime:  8.86\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.7325\n",
      "Runtime:  109.12\n",
      "Percent: [--------------------------------------> ] 99%Runtime:  46.91\n",
      "Percent: [--------------------------------------->] 100%Average excursion length:  14.0\n",
      "Runtime:  51.3\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.0155\n",
      "Runtime:  9.04\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.724\n",
      "Runtime:  110.93\n",
      "Percent: [--------------------------------------->] 100%Runtime:  39.57\n",
      "Percent: [--------------------------------------> ] 98%Average excursion length:  10.0\n",
      "Runtime:  41.05\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.0185\n",
      "Runtime:  8.86\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.7305\n",
      "Runtime:  109.01\n",
      "Percent: [--------------------------------------->] 99%Runtime:  35.85\n",
      "Percent: [--------------------------------------->] 99%Average excursion length:  11.0\n",
      "Runtime:  33.57\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.0205\n",
      "Runtime:  9.04\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.7295\n",
      "Runtime:  104.84\n",
      "Percent: [--------------------------------------> ] 98%Runtime:  34.4\n",
      "Percent: [--------------------------------------->] 100%Average excursion length:  12.0\n",
      "Runtime:  41.3\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.0215\n",
      "Runtime:  8.89\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.746\n",
      "Runtime:  110.24\n",
      "Percent: [--------------------------------------->] 100%Runtime:  38.26\n",
      "Percent: [--------------------------------------->] 99%Average excursion length:  13.0\n",
      "Runtime:  39.74\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.0135\n",
      "Runtime:  8.92\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.757\n",
      "Runtime:  109.93\n",
      "Percent: [--------------------------------------->] 100%Runtime:  31.79\n",
      "Percent: [--------------------------------------->] 100%Average excursion length:  12.0\n",
      "Runtime:  43.49\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.012\n",
      "Runtime:  8.49\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.756\n",
      "Runtime:  110.84\n",
      "Percent: [--------------------------------------->] 100%Runtime:  33.54\n",
      "Percent: [--------------------------------------->] 100%Average excursion length:  10.0\n",
      "Runtime:  34.68\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.025\n",
      "Runtime:  9.16\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.774\n",
      "Runtime:  114.88\n",
      "Percent: [--------------------------------------->] 99%Runtime:  34.2\n",
      "Percent: [--------------------------------------->] 100%Average excursion length:  9.0\n",
      "Runtime:  37.13\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.03\n",
      "Runtime:  9.02\n",
      "Percent: [--------------------------------------->] 100%\n",
      "Acceptance ratio:  0.7595\n",
      "Runtime:  112.33\n",
      "Percent: [--------------------------------------->] 99%Runtime:  34.85\n",
      "Percent: [--------------------------------------->] 100%Average excursion length:  11.0\n",
      "Runtime:  37.42\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (random walk sampler):  3.263510694431354\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (Pointwise sampler):  1.1625137183008534\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (Zanella sampler):  1.4690466851138622\n",
      "-------------------------------------------------------------------\n",
      "-------------------------------------------------------------------\n",
      "The scale reduction for the energy of the target_density (Tabu sampler):  1.3831952448907399\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Running the Gelman-Rubin diagnostic for all four samplers for N=1000\n",
    "n = int(1e3)\n",
    "print_rate = 10\n",
    "T_z = 15\n",
    "T_t = 30\n",
    "thin_rate_t = 0.03\n",
    "thin_rate_z = 0.015\n",
    "traces_rw = []\n",
    "traces_pw = []\n",
    "traces_z = []\n",
    "traces_t = []\n",
    "m = 10\n",
    "for i in np.arange(0,m):\n",
    "    #Run the random walk sampler\n",
    "    trace_rw, energy_rw, hamming_rw, num_acc_rw, runtime_rw = rw_sampler(2*n, N_1, N_2, lmbd, p_match, M_truth, starting_M[i,:], starting_M_reverse[i,:], p_cat, l, beta, x, y, print_rate=10)\n",
    "    #Run the pointwise sampler\n",
    "    trace1_pw, energy_pw, hamming_pw, num_iter_pw, runtime_pw = pointwise_sampler(2*n, N_1, N_2, lmbd, p_match, g, M_truth, starting_M[i,:],\n",
    "                                                                              starting_M_reverse[i,:], p_cat, l, beta, x, y, print_rate)\n",
    "    \n",
    "    #Run the Zanella sampler\n",
    "    trace1_z, energy_z, hamming_z, num_iter_z, runtime_z = zanella_sampler(N_1, N_2,\n",
    "                                                                                num_gens,\n",
    "                                                                                starting_M[i,:], starting_M_reverse[i,:],\n",
    "                                                                                g, 2*T_z, M_truth,\n",
    "                                                                                thin_rate_z, print_rate, lmbd, p_match,\n",
    "                                                                                l, p_cat, beta, x, y)\n",
    "    \n",
    "    #Run the Tabu sampler\n",
    "    trace_t, energy_t, hamming_t, alpha_t, num_iter_t, runtime_t = tabu_sampler(N_1, N_2, num_gens, starting_M[i,:], starting_M_reverse[i,:], g,\n",
    "                                                                    2*T_t, M_truth, thin_rate_t, print_rate, lmbd, p_match, l, p_cat, beta, x, y)\n",
    "    traces_rw.append(energy_rw)\n",
    "    traces_pw.append(energy_pw)\n",
    "    traces_z.append(energy_z)\n",
    "    traces_t.append(energy_t)\n",
    "    \n",
    "#Testing the function to make the code scaleable\n",
    "R_energy_rw = gelman_rubin(traces_rw, n, m)\n",
    "R_energy_pw = gelman_rubin(traces_pw, n, m)\n",
    "R_energy_z = gelman_rubin(traces_z, n, m)\n",
    "R_energy_t = gelman_rubin(traces_t, n, m)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (random walk sampler): \",R_energy_rw)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (Pointwise sampler): \",R_energy_pw)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (Zanella sampler): \",R_energy_z)\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"The scale reduction for the energy of the target_density (Tabu sampler): \",R_energy_t)\n",
    "print(\"-------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f12ece7220a934ac2e09e366950125638378bdec382779a6c1044f75e14f975b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
